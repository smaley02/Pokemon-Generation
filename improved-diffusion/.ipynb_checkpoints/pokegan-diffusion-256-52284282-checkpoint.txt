Mon Dec  9 14:41:00 EST 2024
c1007a-s17.ufhpc
/home/smaley/rcstudents_blue/pokegan/improved-diffusion
Logging to log_256
creating model and diffusion...
creating data loader...
training...
loading model from checkpoint: /blue/rcstudents/smaley/pokegan/improved-diffusion/log_256/model_ckpts/model990000.pt...
/blue/rcstudents/smaley/pokegan/improved-diffusion/improved_diffusion/dist_util.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return th.load(io.BytesIO(data), **kwargs)
loading optimizer state from checkpoint: /blue/rcstudents/smaley/pokegan/improved-diffusion/log_256/model_ckpts/opt990000.pt
/blue/rcstudents/smaley/pokegan/improved-diffusion/improved_diffusion/dist_util.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return th.load(io.BytesIO(data), **kwargs)
loading EMA from checkpoint: /blue/rcstudents/smaley/pokegan/improved-diffusion/log_256/model_ckpts/ema_0.9999_990000.pt...
------------------------
| grad_norm | 0.0105   |
| loss      | 0.00243  |
| loss_q0   | 0.0195   |
| loss_q1   | 0.00253  |
| loss_q2   | 0.000957 |
| loss_q3   | 0.000251 |
| mse       | 0.00243  |
| mse_q0    | 0.0195   |
| mse_q1    | 0.00253  |
| mse_q2    | 0.000957 |
| mse_q3    | 0.000251 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 0.00536  |
| loss      | 0.00192  |
| loss_q0   | 0.00334  |
| loss_q1   | 0.00297  |
| loss_q2   | 0.000972 |
| loss_q3   | 8.32e-05 |
| mse       | 0.00192  |
| mse_q0    | 0.00334  |
| mse_q1    | 0.00297  |
| mse_q2    | 0.000972 |
| mse_q3    | 8.32e-05 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00551  |
| loss      | 0.00195  |
| loss_q0   | 0.00363  |
| loss_q1   | 0.00306  |
| loss_q2   | 0.00104  |
| loss_q3   | 9.59e-05 |
| mse       | 0.00195  |
| mse_q0    | 0.00363  |
| mse_q1    | 0.00306  |
| mse_q2    | 0.00104  |
| mse_q3    | 9.59e-05 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00549  |
| loss      | 0.00193  |
| loss_q0   | 0.00421  |
| loss_q1   | 0.00282  |
| loss_q2   | 0.00106  |
| loss_q3   | 0.000121 |
| mse       | 0.00193  |
| mse_q0    | 0.00421  |
| mse_q1    | 0.00282  |
| mse_q2    | 0.00106  |
| mse_q3    | 0.000121 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00537  |
| loss      | 0.00179  |
| loss_q0   | 0.00342  |
| loss_q1   | 0.0033   |
| loss_q2   | 0.00118  |
| loss_q3   | 7.89e-05 |
| mse       | 0.00179  |
| mse_q0    | 0.00342  |
| mse_q1    | 0.0033   |
| mse_q2    | 0.00118  |
| mse_q3    | 7.89e-05 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00815  |
| loss      | 0.00235  |
| loss_q0   | 0.00577  |
| loss_q1   | 0.00286  |
| loss_q2   | 0.000921 |
| loss_q3   | 8.1e-05  |
| mse       | 0.00235  |
| mse_q0    | 0.00577  |
| mse_q1    | 0.00286  |
| mse_q2    | 0.000921 |
| mse_q3    | 8.1e-05  |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00654  |
| loss      | 0.00195  |
| loss_q0   | 0.00342  |
| loss_q1   | 0.0028   |
| loss_q2   | 0.00104  |
| loss_q3   | 9e-05    |
| mse       | 0.00195  |
| mse_q0    | 0.00342  |
| mse_q1    | 0.0028   |
| mse_q2    | 0.00104  |
| mse_q3    | 9e-05    |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00613  |
| loss      | 0.00216  |
| loss_q0   | 0.0038   |
| loss_q1   | 0.00303  |
| loss_q2   | 0.00142  |
| loss_q3   | 9.51e-05 |
| mse       | 0.00216  |
| mse_q0    | 0.0038   |
| mse_q1    | 0.00303  |
| mse_q2    | 0.00142  |
| mse_q3    | 9.51e-05 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00554  |
| loss      | 0.00184  |
| loss_q0   | 0.00332  |
| loss_q1   | 0.00307  |
| loss_q2   | 0.00102  |
| loss_q3   | 0.000138 |
| mse       | 0.00184  |
| mse_q0    | 0.00332  |
| mse_q1    | 0.00307  |
| mse_q2    | 0.00102  |
| mse_q3    | 0.000138 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00548  |
| loss      | 0.00193  |
| loss_q0   | 0.00367  |
| loss_q1   | 0.00309  |
| loss_q2   | 0.00101  |
| loss_q3   | 7.26e-05 |
| mse       | 0.00193  |
| mse_q0    | 0.00367  |
| mse_q1    | 0.00309  |
| mse_q2    | 0.00101  |
| mse_q3    | 7.26e-05 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00818  |
| loss      | 0.00204  |
| loss_q0   | 0.00452  |
| loss_q1   | 0.00273  |
| loss_q2   | 0.00117  |
| loss_q3   | 9.98e-05 |
| mse       | 0.00204  |
| mse_q0    | 0.00452  |
| mse_q1    | 0.00273  |
| mse_q2    | 0.00117  |
| mse_q3    | 9.98e-05 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00579  |
| loss      | 0.00187  |
| loss_q0   | 0.00358  |
| loss_q1   | 0.0031   |
| loss_q2   | 0.00131  |
| loss_q3   | 0.000108 |
| mse       | 0.00187  |
| mse_q0    | 0.00358  |
| mse_q1    | 0.0031   |
| mse_q2    | 0.00131  |
| mse_q3    | 0.000108 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00533  |
| loss      | 0.00175  |
| loss_q0   | 0.00361  |
| loss_q1   | 0.00267  |
| loss_q2   | 0.00087  |
| loss_q3   | 0.000133 |
| mse       | 0.00175  |
| mse_q0    | 0.00361  |
| mse_q1    | 0.00267  |
| mse_q2    | 0.00087  |
| mse_q3    | 0.000133 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00762  |
| loss      | 0.0022   |
| loss_q0   | 0.00382  |
| loss_q1   | 0.00359  |
| loss_q2   | 0.00143  |
| loss_q3   | 8.05e-05 |
| mse       | 0.0022   |
| mse_q0    | 0.00382  |
| mse_q1    | 0.00359  |
| mse_q2    | 0.00143  |
| mse_q3    | 8.05e-05 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.0078   |
| loss      | 0.00209  |
| loss_q0   | 0.00383  |
| loss_q1   | 0.0031   |
| loss_q2   | 0.000911 |
| loss_q3   | 0.000104 |
| mse       | 0.00209  |
| mse_q0    | 0.00383  |
| mse_q1    | 0.0031   |
| mse_q2    | 0.000911 |
| mse_q3    | 0.000104 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00888  |
| loss      | 0.00187  |
| loss_q0   | 0.00401  |
| loss_q1   | 0.00276  |
| loss_q2   | 0.00101  |
| loss_q3   | 9.85e-05 |
| mse       | 0.00187  |
| mse_q0    | 0.00401  |
| mse_q1    | 0.00276  |
| mse_q2    | 0.00101  |
| mse_q3    | 9.85e-05 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.0066   |
| loss      | 0.00207  |
| loss_q0   | 0.00383  |
| loss_q1   | 0.00304  |
| loss_q2   | 0.000923 |
| loss_q3   | 9.95e-05 |
| mse       | 0.00207  |
| mse_q0    | 0.00383  |
| mse_q1    | 0.00304  |
| mse_q2    | 0.000923 |
| mse_q3    | 9.95e-05 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00559  |
| loss      | 0.00199  |
| loss_q0   | 0.00393  |
| loss_q1   | 0.00291  |
| loss_q2   | 0.00127  |
| loss_q3   | 9.51e-05 |
| mse       | 0.00199  |
| mse_q0    | 0.00393  |
| mse_q1    | 0.00291  |
| mse_q2    | 0.00127  |
| mse_q3    | 9.51e-05 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00518  |
| loss      | 0.0019   |
| loss_q0   | 0.00407  |
| loss_q1   | 0.00271  |
| loss_q2   | 0.00101  |
| loss_q3   | 7.27e-05 |
| mse       | 0.0019   |
| mse_q0    | 0.00407  |
| mse_q1    | 0.00271  |
| mse_q2    | 0.00101  |
| mse_q3    | 7.27e-05 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.005    |
| loss      | 0.00177  |
| loss_q0   | 0.00353  |
| loss_q1   | 0.00267  |
| loss_q2   | 0.00108  |
| loss_q3   | 9.07e-05 |
| mse       | 0.00177  |
| mse_q0    | 0.00353  |
| mse_q1    | 0.00267  |
| mse_q2    | 0.00108  |
| mse_q3    | 9.07e-05 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00717  |
| loss      | 0.00183  |
| loss_q0   | 0.00394  |
| loss_q1   | 0.00256  |
| loss_q2   | 0.000904 |
| loss_q3   | 9.44e-05 |
| mse       | 0.00183  |
| mse_q0    | 0.00394  |
| mse_q1    | 0.00256  |
| mse_q2    | 0.000904 |
| mse_q3    | 9.44e-05 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00489  |
| loss      | 0.00199  |
| loss_q0   | 0.00354  |
| loss_q1   | 0.00312  |
| loss_q2   | 0.00107  |
| loss_q3   | 0.000129 |
| mse       | 0.00199  |
| mse_q0    | 0.00354  |
| mse_q1    | 0.00312  |
| mse_q2    | 0.00107  |
| mse_q3    | 0.000129 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00562  |
| loss      | 0.00182  |
| loss_q0   | 0.00382  |
| loss_q1   | 0.00242  |
| loss_q2   | 0.00124  |
| loss_q3   | 0.000108 |
| mse       | 0.00182  |
| mse_q0    | 0.00382  |
| mse_q1    | 0.00242  |
| mse_q2    | 0.00124  |
| mse_q3    | 0.000108 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00546  |
| loss      | 0.00174  |
| loss_q0   | 0.00307  |
| loss_q1   | 0.0024   |
| loss_q2   | 0.000873 |
| loss_q3   | 0.000109 |
| mse       | 0.00174  |
| mse_q0    | 0.00307  |
| mse_q1    | 0.0024   |
| mse_q2    | 0.000873 |
| mse_q3    | 0.000109 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00647  |
| loss      | 0.00205  |
| loss_q0   | 0.00433  |
| loss_q1   | 0.00305  |
| loss_q2   | 0.00106  |
| loss_q3   | 0.00011  |
| mse       | 0.00205  |
| mse_q0    | 0.00433  |
| mse_q1    | 0.00305  |
| mse_q2    | 0.00106  |
| mse_q3    | 0.00011  |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00664  |
| loss      | 0.00198  |
| loss_q0   | 0.00351  |
| loss_q1   | 0.00299  |
| loss_q2   | 0.00135  |
| loss_q3   | 9.65e-05 |
| mse       | 0.00198  |
| mse_q0    | 0.00351  |
| mse_q1    | 0.00299  |
| mse_q2    | 0.00135  |
| mse_q3    | 9.65e-05 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00614  |
| loss      | 0.00204  |
| loss_q0   | 0.00368  |
| loss_q1   | 0.00318  |
| loss_q2   | 0.00112  |
| loss_q3   | 7.88e-05 |
| mse       | 0.00204  |
| mse_q0    | 0.00368  |
| mse_q1    | 0.00318  |
| mse_q2    | 0.00112  |
| mse_q3    | 7.88e-05 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00633  |
| loss      | 0.00173  |
| loss_q0   | 0.00321  |
| loss_q1   | 0.00302  |
| loss_q2   | 0.00101  |
| loss_q3   | 8.87e-05 |
| mse       | 0.00173  |
| mse_q0    | 0.00321  |
| mse_q1    | 0.00302  |
| mse_q2    | 0.00101  |
| mse_q3    | 8.87e-05 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00647  |
| loss      | 0.002    |
| loss_q0   | 0.00372  |
| loss_q1   | 0.00343  |
| loss_q2   | 0.00101  |
| loss_q3   | 0.000104 |
| mse       | 0.002    |
| mse_q0    | 0.00372  |
| mse_q1    | 0.00343  |
| mse_q2    | 0.00101  |
| mse_q3    | 0.000104 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00751  |
| loss      | 0.0021   |
| loss_q0   | 0.00418  |
| loss_q1   | 0.00265  |
| loss_q2   | 0.00115  |
| loss_q3   | 0.000103 |
| mse       | 0.0021   |
| mse_q0    | 0.00418  |
| mse_q1    | 0.00265  |
| mse_q2    | 0.00115  |
| mse_q3    | 0.000103 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00892  |
| loss      | 0.00196  |
| loss_q0   | 0.00475  |
| loss_q1   | 0.00253  |
| loss_q2   | 0.000901 |
| loss_q3   | 7.83e-05 |
| mse       | 0.00196  |
| mse_q0    | 0.00475  |
| mse_q1    | 0.00253  |
| mse_q2    | 0.000901 |
| mse_q3    | 7.83e-05 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00795  |
| loss      | 0.00199  |
| loss_q0   | 0.00417  |
| loss_q1   | 0.00263  |
| loss_q2   | 0.000908 |
| loss_q3   | 0.000117 |
| mse       | 0.00199  |
| mse_q0    | 0.00417  |
| mse_q1    | 0.00263  |
| mse_q2    | 0.000908 |
| mse_q3    | 0.000117 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.0112   |
| loss      | 0.00223  |
| loss_q0   | 0.00472  |
| loss_q1   | 0.00294  |
| loss_q2   | 0.00129  |
| loss_q3   | 9.82e-05 |
| mse       | 0.00223  |
| mse_q0    | 0.00472  |
| mse_q1    | 0.00294  |
| mse_q2    | 0.00129  |
| mse_q3    | 9.82e-05 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.0092   |
| loss      | 0.00174  |
| loss_q0   | 0.00315  |
| loss_q1   | 0.00284  |
| loss_q2   | 0.000987 |
| loss_q3   | 9.7e-05  |
| mse       | 0.00174  |
| mse_q0    | 0.00315  |
| mse_q1    | 0.00284  |
| mse_q2    | 0.000987 |
| mse_q3    | 9.7e-05  |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.0214   |
| loss      | 0.00364  |
| loss_q0   | 0.00897  |
| loss_q1   | 0.00277  |
| loss_q2   | 0.000826 |
| loss_q3   | 9.26e-05 |
| mse       | 0.00364  |
| mse_q0    | 0.00897  |
| mse_q1    | 0.00277  |
| mse_q2    | 0.000826 |
| mse_q3    | 9.26e-05 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.0103   |
| loss      | 0.00237  |
| loss_q0   | 0.00532  |
| loss_q1   | 0.00321  |
| loss_q2   | 0.00089  |
| loss_q3   | 0.000107 |
| mse       | 0.00237  |
| mse_q0    | 0.00532  |
| mse_q1    | 0.00321  |
| mse_q2    | 0.00089  |
| mse_q3    | 0.000107 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.0085   |
| loss      | 0.002    |
| loss_q0   | 0.00358  |
| loss_q1   | 0.00288  |
| loss_q2   | 0.00112  |
| loss_q3   | 0.000119 |
| mse       | 0.002    |
| mse_q0    | 0.00358  |
| mse_q1    | 0.00288  |
| mse_q2    | 0.00112  |
| mse_q3    | 0.000119 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00937  |
| loss      | 0.00226  |
| loss_q0   | 0.00464  |
| loss_q1   | 0.00285  |
| loss_q2   | 0.00115  |
| loss_q3   | 0.000129 |
| mse       | 0.00226  |
| mse_q0    | 0.00464  |
| mse_q1    | 0.00285  |
| mse_q2    | 0.00115  |
| mse_q3    | 0.000129 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00839  |
| loss      | 0.00183  |
| loss_q0   | 0.00449  |
| loss_q1   | 0.00235  |
| loss_q2   | 0.00101  |
| loss_q3   | 7.11e-05 |
| mse       | 0.00183  |
| mse_q0    | 0.00449  |
| mse_q1    | 0.00235  |
| mse_q2    | 0.00101  |
| mse_q3    | 7.11e-05 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00825  |
| loss      | 0.00238  |
| loss_q0   | 0.0042   |
| loss_q1   | 0.00283  |
| loss_q2   | 0.00128  |
| loss_q3   | 9.9e-05  |
| mse       | 0.00238  |
| mse_q0    | 0.0042   |
| mse_q1    | 0.00283  |
| mse_q2    | 0.00128  |
| mse_q3    | 9.9e-05  |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00803  |
| loss      | 0.00223  |
| loss_q0   | 0.00419  |
| loss_q1   | 0.00358  |
| loss_q2   | 0.000999 |
| loss_q3   | 0.000107 |
| mse       | 0.00223  |
| mse_q0    | 0.00419  |
| mse_q1    | 0.00358  |
| mse_q2    | 0.000999 |
| mse_q3    | 0.000107 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.0069   |
| loss      | 0.00174  |
| loss_q0   | 0.0035   |
| loss_q1   | 0.00289  |
| loss_q2   | 0.000976 |
| loss_q3   | 0.00012  |
| mse       | 0.00174  |
| mse_q0    | 0.0035   |
| mse_q1    | 0.00289  |
| mse_q2    | 0.000976 |
| mse_q3    | 0.00012  |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.0127   |
| loss      | 0.00238  |
| loss_q0   | 0.00429  |
| loss_q1   | 0.00333  |
| loss_q2   | 0.00115  |
| loss_q3   | 0.000109 |
| mse       | 0.00238  |
| mse_q0    | 0.00429  |
| mse_q1    | 0.00333  |
| mse_q2    | 0.00115  |
| mse_q3    | 0.000109 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.0328   |
| loss      | 0.00227  |
| loss_q0   | 0.00484  |
| loss_q1   | 0.00287  |
| loss_q2   | 0.00123  |
| loss_q3   | 0.000166 |
| mse       | 0.00227  |
| mse_q0    | 0.00484  |
| mse_q1    | 0.00287  |
| mse_q2    | 0.00123  |
| mse_q3    | 0.000166 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.018    |
| loss      | 0.00236  |
| loss_q0   | 0.0041   |
| loss_q1   | 0.00338  |
| loss_q2   | 0.00123  |
| loss_q3   | 0.00014  |
| mse       | 0.00236  |
| mse_q0    | 0.0041   |
| mse_q1    | 0.00338  |
| mse_q2    | 0.00123  |
| mse_q3    | 0.00014  |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.0162   |
| loss      | 0.0022   |
| loss_q0   | 0.00492  |
| loss_q1   | 0.0029   |
| loss_q2   | 0.00114  |
| loss_q3   | 0.000127 |
| mse       | 0.0022   |
| mse_q0    | 0.00492  |
| mse_q1    | 0.0029   |
| mse_q2    | 0.00114  |
| mse_q3    | 0.000127 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.0132   |
| loss      | 0.00185  |
| loss_q0   | 0.00396  |
| loss_q1   | 0.00254  |
| loss_q2   | 0.00107  |
| loss_q3   | 0.000116 |
| mse       | 0.00185  |
| mse_q0    | 0.00396  |
| mse_q1    | 0.00254  |
| mse_q2    | 0.00107  |
| mse_q3    | 0.000116 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.0181   |
| loss      | 0.0022   |
| loss_q0   | 0.00578  |
| loss_q1   | 0.00297  |
| loss_q2   | 0.000912 |
| loss_q3   | 0.00012  |
| mse       | 0.0022   |
| mse_q0    | 0.00578  |
| mse_q1    | 0.00297  |
| mse_q2    | 0.000912 |
| mse_q3    | 0.00012  |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.0126   |
| loss      | 0.00252  |
| loss_q0   | 0.00503  |
| loss_q1   | 0.00328  |
| loss_q2   | 0.00113  |
| loss_q3   | 0.000115 |
| mse       | 0.00252  |
| mse_q0    | 0.00503  |
| mse_q1    | 0.00328  |
| mse_q2    | 0.00113  |
| mse_q3    | 0.000115 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00966  |
| loss      | 0.00208  |
| loss_q0   | 0.00373  |
| loss_q1   | 0.00298  |
| loss_q2   | 0.000995 |
| loss_q3   | 0.000115 |
| mse       | 0.00208  |
| mse_q0    | 0.00373  |
| mse_q1    | 0.00298  |
| mse_q2    | 0.000995 |
| mse_q3    | 0.000115 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00757  |
| loss      | 0.00217  |
| loss_q0   | 0.00423  |
| loss_q1   | 0.0033   |
| loss_q2   | 0.00109  |
| loss_q3   | 8.92e-05 |
| mse       | 0.00217  |
| mse_q0    | 0.00423  |
| mse_q1    | 0.0033   |
| mse_q2    | 0.00109  |
| mse_q3    | 8.92e-05 |
| samples   | 1.58e+07 |
| step      | 9.9e+05  |
------------------------
------------------------
| grad_norm | 0.00564  |
| loss      | 0.00207  |
| loss_q0   | 0.00387  |
| loss_q1   | 0.00342  |
| loss_q2   | 0.00118  |
| loss_q3   | 9.4e-05  |
| mse       | 0.00207  |
| mse_q0    | 0.00387  |
| mse_q1    | 0.00342  |
| mse_q2    | 0.00118  |
| mse_q3    | 9.4e-05  |
| samples   | 1.58e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00503  |
| loss      | 0.00187  |
| loss_q0   | 0.0038   |
| loss_q1   | 0.00281  |
| loss_q2   | 0.00114  |
| loss_q3   | 8.98e-05 |
| mse       | 0.00187  |
| mse_q0    | 0.0038   |
| mse_q1    | 0.00281  |
| mse_q2    | 0.00114  |
| mse_q3    | 8.98e-05 |
| samples   | 1.58e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00563  |
| loss      | 0.00214  |
| loss_q0   | 0.00445  |
| loss_q1   | 0.00288  |
| loss_q2   | 0.000895 |
| loss_q3   | 0.000109 |
| mse       | 0.00214  |
| mse_q0    | 0.00445  |
| mse_q1    | 0.00288  |
| mse_q2    | 0.000895 |
| mse_q3    | 0.000109 |
| samples   | 1.58e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00452  |
| loss      | 0.00163  |
| loss_q0   | 0.00311  |
| loss_q1   | 0.00255  |
| loss_q2   | 0.000848 |
| loss_q3   | 9.98e-05 |
| mse       | 0.00163  |
| mse_q0    | 0.00311  |
| mse_q1    | 0.00255  |
| mse_q2    | 0.000848 |
| mse_q3    | 9.98e-05 |
| samples   | 1.58e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00452  |
| loss      | 0.00166  |
| loss_q0   | 0.00337  |
| loss_q1   | 0.0028   |
| loss_q2   | 0.00102  |
| loss_q3   | 0.000112 |
| mse       | 0.00166  |
| mse_q0    | 0.00337  |
| mse_q1    | 0.0028   |
| mse_q2    | 0.00102  |
| mse_q3    | 0.000112 |
| samples   | 1.58e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00466  |
| loss      | 0.00194  |
| loss_q0   | 0.00353  |
| loss_q1   | 0.00248  |
| loss_q2   | 0.00108  |
| loss_q3   | 0.0001   |
| mse       | 0.00194  |
| mse_q0    | 0.00353  |
| mse_q1    | 0.00248  |
| mse_q2    | 0.00108  |
| mse_q3    | 0.0001   |
| samples   | 1.58e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.0063   |
| loss      | 0.00239  |
| loss_q0   | 0.005    |
| loss_q1   | 0.00316  |
| loss_q2   | 0.000851 |
| loss_q3   | 0.000143 |
| mse       | 0.00239  |
| mse_q0    | 0.005    |
| mse_q1    | 0.00316  |
| mse_q2    | 0.000851 |
| mse_q3    | 0.000143 |
| samples   | 1.58e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00575  |
| loss      | 0.00172  |
| loss_q0   | 0.00319  |
| loss_q1   | 0.00273  |
| loss_q2   | 0.000923 |
| loss_q3   | 0.000104 |
| mse       | 0.00172  |
| mse_q0    | 0.00319  |
| mse_q1    | 0.00273  |
| mse_q2    | 0.000923 |
| mse_q3    | 0.000104 |
| samples   | 1.58e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00694  |
| loss      | 0.00215  |
| loss_q0   | 0.00416  |
| loss_q1   | 0.00275  |
| loss_q2   | 0.00113  |
| loss_q3   | 9.91e-05 |
| mse       | 0.00215  |
| mse_q0    | 0.00416  |
| mse_q1    | 0.00275  |
| mse_q2    | 0.00113  |
| mse_q3    | 9.91e-05 |
| samples   | 1.58e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00584  |
| loss      | 0.00215  |
| loss_q0   | 0.00463  |
| loss_q1   | 0.00297  |
| loss_q2   | 0.0012   |
| loss_q3   | 0.000108 |
| mse       | 0.00215  |
| mse_q0    | 0.00463  |
| mse_q1    | 0.00297  |
| mse_q2    | 0.0012   |
| mse_q3    | 0.000108 |
| samples   | 1.58e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00495  |
| loss      | 0.00185  |
| loss_q0   | 0.00304  |
| loss_q1   | 0.0028   |
| loss_q2   | 0.00131  |
| loss_q3   | 0.000124 |
| mse       | 0.00185  |
| mse_q0    | 0.00304  |
| mse_q1    | 0.0028   |
| mse_q2    | 0.00131  |
| mse_q3    | 0.000124 |
| samples   | 1.58e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00482  |
| loss      | 0.00181  |
| loss_q0   | 0.00424  |
| loss_q1   | 0.00281  |
| loss_q2   | 0.00116  |
| loss_q3   | 6.75e-05 |
| mse       | 0.00181  |
| mse_q0    | 0.00424  |
| mse_q1    | 0.00281  |
| mse_q2    | 0.00116  |
| mse_q3    | 6.75e-05 |
| samples   | 1.58e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00501  |
| loss      | 0.002    |
| loss_q0   | 0.00422  |
| loss_q1   | 0.00291  |
| loss_q2   | 0.00123  |
| loss_q3   | 0.000101 |
| mse       | 0.002    |
| mse_q0    | 0.00422  |
| mse_q1    | 0.00291  |
| mse_q2    | 0.00123  |
| mse_q3    | 0.000101 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00451  |
| loss      | 0.00184  |
| loss_q0   | 0.00386  |
| loss_q1   | 0.0026   |
| loss_q2   | 0.00112  |
| loss_q3   | 8.87e-05 |
| mse       | 0.00184  |
| mse_q0    | 0.00386  |
| mse_q1    | 0.0026   |
| mse_q2    | 0.00112  |
| mse_q3    | 8.87e-05 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00535  |
| loss      | 0.00212  |
| loss_q0   | 0.00389  |
| loss_q1   | 0.00353  |
| loss_q2   | 0.00111  |
| loss_q3   | 8.06e-05 |
| mse       | 0.00212  |
| mse_q0    | 0.00389  |
| mse_q1    | 0.00353  |
| mse_q2    | 0.00111  |
| mse_q3    | 8.06e-05 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00482  |
| loss      | 0.00184  |
| loss_q0   | 0.00319  |
| loss_q1   | 0.00259  |
| loss_q2   | 0.000904 |
| loss_q3   | 7.84e-05 |
| mse       | 0.00184  |
| mse_q0    | 0.00319  |
| mse_q1    | 0.00259  |
| mse_q2    | 0.000904 |
| mse_q3    | 7.84e-05 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00625  |
| loss      | 0.00197  |
| loss_q0   | 0.00343  |
| loss_q1   | 0.00349  |
| loss_q2   | 0.00107  |
| loss_q3   | 7.95e-05 |
| mse       | 0.00197  |
| mse_q0    | 0.00343  |
| mse_q1    | 0.00349  |
| mse_q2    | 0.00107  |
| mse_q3    | 7.95e-05 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00505  |
| loss      | 0.00172  |
| loss_q0   | 0.00362  |
| loss_q1   | 0.00327  |
| loss_q2   | 0.00103  |
| loss_q3   | 7.52e-05 |
| mse       | 0.00172  |
| mse_q0    | 0.00362  |
| mse_q1    | 0.00327  |
| mse_q2    | 0.00103  |
| mse_q3    | 7.52e-05 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00573  |
| loss      | 0.00184  |
| loss_q0   | 0.0036   |
| loss_q1   | 0.00258  |
| loss_q2   | 0.00112  |
| loss_q3   | 0.000106 |
| mse       | 0.00184  |
| mse_q0    | 0.0036   |
| mse_q1    | 0.00258  |
| mse_q2    | 0.00112  |
| mse_q3    | 0.000106 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00477  |
| loss      | 0.00183  |
| loss_q0   | 0.00396  |
| loss_q1   | 0.00298  |
| loss_q2   | 0.00112  |
| loss_q3   | 0.00011  |
| mse       | 0.00183  |
| mse_q0    | 0.00396  |
| mse_q1    | 0.00298  |
| mse_q2    | 0.00112  |
| mse_q3    | 0.00011  |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00493  |
| loss      | 0.00198  |
| loss_q0   | 0.00324  |
| loss_q1   | 0.00328  |
| loss_q2   | 0.000879 |
| loss_q3   | 8.74e-05 |
| mse       | 0.00198  |
| mse_q0    | 0.00324  |
| mse_q1    | 0.00328  |
| mse_q2    | 0.000879 |
| mse_q3    | 8.74e-05 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00465  |
| loss      | 0.00165  |
| loss_q0   | 0.00349  |
| loss_q1   | 0.00277  |
| loss_q2   | 0.00102  |
| loss_q3   | 9.1e-05  |
| mse       | 0.00165  |
| mse_q0    | 0.00349  |
| mse_q1    | 0.00277  |
| mse_q2    | 0.00102  |
| mse_q3    | 9.1e-05  |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00537  |
| loss      | 0.00195  |
| loss_q0   | 0.00353  |
| loss_q1   | 0.00305  |
| loss_q2   | 0.00094  |
| loss_q3   | 0.00012  |
| mse       | 0.00195  |
| mse_q0    | 0.00353  |
| mse_q1    | 0.00305  |
| mse_q2    | 0.00094  |
| mse_q3    | 0.00012  |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00954  |
| loss      | 0.00267  |
| loss_q0   | 0.00544  |
| loss_q1   | 0.00328  |
| loss_q2   | 0.00109  |
| loss_q3   | 7.33e-05 |
| mse       | 0.00267  |
| mse_q0    | 0.00544  |
| mse_q1    | 0.00328  |
| mse_q2    | 0.00109  |
| mse_q3    | 7.33e-05 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00726  |
| loss      | 0.00183  |
| loss_q0   | 0.00393  |
| loss_q1   | 0.00278  |
| loss_q2   | 0.000912 |
| loss_q3   | 9.87e-05 |
| mse       | 0.00183  |
| mse_q0    | 0.00393  |
| mse_q1    | 0.00278  |
| mse_q2    | 0.000912 |
| mse_q3    | 9.87e-05 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00809  |
| loss      | 0.00226  |
| loss_q0   | 0.00454  |
| loss_q1   | 0.00293  |
| loss_q2   | 0.00109  |
| loss_q3   | 0.000144 |
| mse       | 0.00226  |
| mse_q0    | 0.00454  |
| mse_q1    | 0.00293  |
| mse_q2    | 0.00109  |
| mse_q3    | 0.000144 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00949  |
| loss      | 0.0022   |
| loss_q0   | 0.00483  |
| loss_q1   | 0.00318  |
| loss_q2   | 0.00101  |
| loss_q3   | 0.000133 |
| mse       | 0.0022   |
| mse_q0    | 0.00483  |
| mse_q1    | 0.00318  |
| mse_q2    | 0.00101  |
| mse_q3    | 0.000133 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00645  |
| loss      | 0.00207  |
| loss_q0   | 0.00389  |
| loss_q1   | 0.00305  |
| loss_q2   | 0.00112  |
| loss_q3   | 0.0001   |
| mse       | 0.00207  |
| mse_q0    | 0.00389  |
| mse_q1    | 0.00305  |
| mse_q2    | 0.00112  |
| mse_q3    | 0.0001   |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00716  |
| loss      | 0.00195  |
| loss_q0   | 0.00426  |
| loss_q1   | 0.0026   |
| loss_q2   | 0.0011   |
| loss_q3   | 8.03e-05 |
| mse       | 0.00195  |
| mse_q0    | 0.00426  |
| mse_q1    | 0.0026   |
| mse_q2    | 0.0011   |
| mse_q3    | 8.03e-05 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00536  |
| loss      | 0.00216  |
| loss_q0   | 0.00372  |
| loss_q1   | 0.00333  |
| loss_q2   | 0.00121  |
| loss_q3   | 9.63e-05 |
| mse       | 0.00216  |
| mse_q0    | 0.00372  |
| mse_q1    | 0.00333  |
| mse_q2    | 0.00121  |
| mse_q3    | 9.63e-05 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.0053   |
| loss      | 0.00196  |
| loss_q0   | 0.00353  |
| loss_q1   | 0.00317  |
| loss_q2   | 0.0012   |
| loss_q3   | 8.4e-05  |
| mse       | 0.00196  |
| mse_q0    | 0.00353  |
| mse_q1    | 0.00317  |
| mse_q2    | 0.0012   |
| mse_q3    | 8.4e-05  |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00463  |
| loss      | 0.00203  |
| loss_q0   | 0.00398  |
| loss_q1   | 0.00292  |
| loss_q2   | 0.00123  |
| loss_q3   | 8.88e-05 |
| mse       | 0.00203  |
| mse_q0    | 0.00398  |
| mse_q1    | 0.00292  |
| mse_q2    | 0.00123  |
| mse_q3    | 8.88e-05 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00671  |
| loss      | 0.00239  |
| loss_q0   | 0.0049   |
| loss_q1   | 0.00284  |
| loss_q2   | 0.00118  |
| loss_q3   | 8.24e-05 |
| mse       | 0.00239  |
| mse_q0    | 0.0049   |
| mse_q1    | 0.00284  |
| mse_q2    | 0.00118  |
| mse_q3    | 8.24e-05 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00456  |
| loss      | 0.00195  |
| loss_q0   | 0.00312  |
| loss_q1   | 0.0033   |
| loss_q2   | 0.0012   |
| loss_q3   | 0.000104 |
| mse       | 0.00195  |
| mse_q0    | 0.00312  |
| mse_q1    | 0.0033   |
| mse_q2    | 0.0012   |
| mse_q3    | 0.000104 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.0061   |
| loss      | 0.00213  |
| loss_q0   | 0.00415  |
| loss_q1   | 0.00281  |
| loss_q2   | 0.000828 |
| loss_q3   | 0.000113 |
| mse       | 0.00213  |
| mse_q0    | 0.00415  |
| mse_q1    | 0.00281  |
| mse_q2    | 0.000828 |
| mse_q3    | 0.000113 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00485  |
| loss      | 0.0018   |
| loss_q0   | 0.00333  |
| loss_q1   | 0.00281  |
| loss_q2   | 0.000997 |
| loss_q3   | 8.4e-05  |
| mse       | 0.0018   |
| mse_q0    | 0.00333  |
| mse_q1    | 0.00281  |
| mse_q2    | 0.000997 |
| mse_q3    | 8.4e-05  |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00459  |
| loss      | 0.00183  |
| loss_q0   | 0.00361  |
| loss_q1   | 0.00258  |
| loss_q2   | 0.00114  |
| loss_q3   | 8.42e-05 |
| mse       | 0.00183  |
| mse_q0    | 0.00361  |
| mse_q1    | 0.00258  |
| mse_q2    | 0.00114  |
| mse_q3    | 8.42e-05 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00696  |
| loss      | 0.002    |
| loss_q0   | 0.00449  |
| loss_q1   | 0.0027   |
| loss_q2   | 0.000933 |
| loss_q3   | 8.29e-05 |
| mse       | 0.002    |
| mse_q0    | 0.00449  |
| mse_q1    | 0.0027   |
| mse_q2    | 0.000933 |
| mse_q3    | 8.29e-05 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00735  |
| loss      | 0.00217  |
| loss_q0   | 0.00487  |
| loss_q1   | 0.00271  |
| loss_q2   | 0.00101  |
| loss_q3   | 9.5e-05  |
| mse       | 0.00217  |
| mse_q0    | 0.00487  |
| mse_q1    | 0.00271  |
| mse_q2    | 0.00101  |
| mse_q3    | 9.5e-05  |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00501  |
| loss      | 0.00181  |
| loss_q0   | 0.00314  |
| loss_q1   | 0.00335  |
| loss_q2   | 0.0015   |
| loss_q3   | 8.63e-05 |
| mse       | 0.00181  |
| mse_q0    | 0.00314  |
| mse_q1    | 0.00335  |
| mse_q2    | 0.0015   |
| mse_q3    | 8.63e-05 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00395  |
| loss      | 0.00194  |
| loss_q0   | 0.00354  |
| loss_q1   | 0.003    |
| loss_q2   | 0.0012   |
| loss_q3   | 7.44e-05 |
| mse       | 0.00194  |
| mse_q0    | 0.00354  |
| mse_q1    | 0.003    |
| mse_q2    | 0.0012   |
| mse_q3    | 7.44e-05 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00525  |
| loss      | 0.00206  |
| loss_q0   | 0.00344  |
| loss_q1   | 0.00309  |
| loss_q2   | 0.00128  |
| loss_q3   | 0.000123 |
| mse       | 0.00206  |
| mse_q0    | 0.00344  |
| mse_q1    | 0.00309  |
| mse_q2    | 0.00128  |
| mse_q3    | 0.000123 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.0046   |
| loss      | 0.00175  |
| loss_q0   | 0.00305  |
| loss_q1   | 0.00259  |
| loss_q2   | 0.000968 |
| loss_q3   | 8e-05    |
| mse       | 0.00175  |
| mse_q0    | 0.00305  |
| mse_q1    | 0.00259  |
| mse_q2    | 0.000968 |
| mse_q3    | 8e-05    |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00491  |
| loss      | 0.00186  |
| loss_q0   | 0.00415  |
| loss_q1   | 0.00289  |
| loss_q2   | 0.00119  |
| loss_q3   | 0.000105 |
| mse       | 0.00186  |
| mse_q0    | 0.00415  |
| mse_q1    | 0.00289  |
| mse_q2    | 0.00119  |
| mse_q3    | 0.000105 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00752  |
| loss      | 0.00221  |
| loss_q0   | 0.00476  |
| loss_q1   | 0.00306  |
| loss_q2   | 0.00115  |
| loss_q3   | 0.000141 |
| mse       | 0.00221  |
| mse_q0    | 0.00476  |
| mse_q1    | 0.00306  |
| mse_q2    | 0.00115  |
| mse_q3    | 0.000141 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00897  |
| loss      | 0.0025   |
| loss_q0   | 0.00551  |
| loss_q1   | 0.0029   |
| loss_q2   | 0.00107  |
| loss_q3   | 0.00014  |
| mse       | 0.0025   |
| mse_q0    | 0.00551  |
| mse_q1    | 0.0029   |
| mse_q2    | 0.00107  |
| mse_q3    | 0.00014  |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00579  |
| loss      | 0.00224  |
| loss_q0   | 0.00434  |
| loss_q1   | 0.00272  |
| loss_q2   | 0.00102  |
| loss_q3   | 7.87e-05 |
| mse       | 0.00224  |
| mse_q0    | 0.00434  |
| mse_q1    | 0.00272  |
| mse_q2    | 0.00102  |
| mse_q3    | 7.87e-05 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00845  |
| loss      | 0.00216  |
| loss_q0   | 0.00399  |
| loss_q1   | 0.0029   |
| loss_q2   | 0.00116  |
| loss_q3   | 0.000109 |
| mse       | 0.00216  |
| mse_q0    | 0.00399  |
| mse_q1    | 0.0029   |
| mse_q2    | 0.00116  |
| mse_q3    | 0.000109 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00748  |
| loss      | 0.002    |
| loss_q0   | 0.00373  |
| loss_q1   | 0.00306  |
| loss_q2   | 0.00111  |
| loss_q3   | 0.000103 |
| mse       | 0.002    |
| mse_q0    | 0.00373  |
| mse_q1    | 0.00306  |
| mse_q2    | 0.00111  |
| mse_q3    | 0.000103 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00636  |
| loss      | 0.00198  |
| loss_q0   | 0.00357  |
| loss_q1   | 0.00266  |
| loss_q2   | 0.00101  |
| loss_q3   | 0.000113 |
| mse       | 0.00198  |
| mse_q0    | 0.00357  |
| mse_q1    | 0.00266  |
| mse_q2    | 0.00101  |
| mse_q3    | 0.000113 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00413  |
| loss      | 0.00168  |
| loss_q0   | 0.00299  |
| loss_q1   | 0.00257  |
| loss_q2   | 0.000845 |
| loss_q3   | 0.000114 |
| mse       | 0.00168  |
| mse_q0    | 0.00299  |
| mse_q1    | 0.00257  |
| mse_q2    | 0.000845 |
| mse_q3    | 0.000114 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00804  |
| loss      | 0.00253  |
| loss_q0   | 0.00518  |
| loss_q1   | 0.00286  |
| loss_q2   | 0.00127  |
| loss_q3   | 0.000122 |
| mse       | 0.00253  |
| mse_q0    | 0.00518  |
| mse_q1    | 0.00286  |
| mse_q2    | 0.00127  |
| mse_q3    | 0.000122 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00639  |
| loss      | 0.00177  |
| loss_q0   | 0.0033   |
| loss_q1   | 0.00253  |
| loss_q2   | 0.000897 |
| loss_q3   | 0.000108 |
| mse       | 0.00177  |
| mse_q0    | 0.0033   |
| mse_q1    | 0.00253  |
| mse_q2    | 0.000897 |
| mse_q3    | 0.000108 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
------------------------
| grad_norm | 0.00524  |
| loss      | 0.00186  |
| loss_q0   | 0.00366  |
| loss_q1   | 0.00315  |
| loss_q2   | 0.00106  |
| loss_q3   | 0.000105 |
| mse       | 0.00186  |
| mse_q0    | 0.00366  |
| mse_q1    | 0.00315  |
| mse_q2    | 0.00106  |
| mse_q3    | 0.000105 |
| samples   | 1.59e+07 |
| step      | 9.91e+05 |
------------------------
