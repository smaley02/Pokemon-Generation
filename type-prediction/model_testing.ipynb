{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b2e5d63-f904-4553-a146-f68d9dd6e95c",
   "metadata": {},
   "source": [
    "From the dataset we observe a few things:\n",
    "- This is a multilabel image classification problem\n",
    "    - one or two possible types per image, so not multiclass\n",
    "- We could make this multiclass if we consider combination types as their own class\n",
    "    - not sure tho\n",
    "- there is a class imbalance, far more normal and water types. And ice types are a fifth the size of the largest class\n",
    "- This [guide](https://www.analyticsvidhya.com/blog/2019/04/build-first-multi-label-image-classification-model-python/) will help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2608644b-6709-4643-8186-b760b320d303",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- one model for each type, which will give a probablity score for each class\n",
    "- the top two classes for each image will be the predicted types\n",
    "    - the second type will have to be above a certain threshold else one type is predicted\n",
    "    - Our class probabilities are independent of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d4915a-2d16-4e9c-9cb8-5ea19d2f1de3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eaddf81-74b9-4e60-b4b8-7de0a4f060cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6d914ff-bcaa-4908-a03e-8b42befd66c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Type</th>\n",
       "      <th>normal</th>\n",
       "      <th>fire</th>\n",
       "      <th>water</th>\n",
       "      <th>grass</th>\n",
       "      <th>electric</th>\n",
       "      <th>ice</th>\n",
       "      <th>fighting</th>\n",
       "      <th>poison</th>\n",
       "      <th>ground</th>\n",
       "      <th>flying</th>\n",
       "      <th>psychic</th>\n",
       "      <th>bug</th>\n",
       "      <th>rock</th>\n",
       "      <th>ghost</th>\n",
       "      <th>dragon</th>\n",
       "      <th>dark</th>\n",
       "      <th>steel</th>\n",
       "      <th>fairy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110.95</td>\n",
       "      <td>poison, ground</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>155.408</td>\n",
       "      <td>fire, fairy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360.381</td>\n",
       "      <td>grass, psychic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.142e</td>\n",
       "      <td>fire, flying</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>289.175</td>\n",
       "      <td>bug, fairy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key            Type  normal  fire  water  grass  electric  ice  \\\n",
       "0   110.95  poison, ground       0     0      0      0         0    0   \n",
       "1  155.408     fire, fairy       0     1      0      0         0    0   \n",
       "2  360.381  grass, psychic       0     0      0      1         0    0   \n",
       "3   6.142e    fire, flying       0     1      0      0         0    0   \n",
       "4  289.175      bug, fairy       0     0      0      0         0    0   \n",
       "\n",
       "   fighting  poison  ground  flying  psychic  bug  rock  ghost  dragon  dark  \\\n",
       "0         0       1       1       0        0    0     0      0       0     0   \n",
       "1         0       0       0       0        0    0     0      0       0     0   \n",
       "2         0       0       0       0        1    0     0      0       0     0   \n",
       "3         0       0       0       1        0    0     0      0       0     0   \n",
       "4         0       0       0       0        0    1     0      0       0     0   \n",
       "\n",
       "   steel  fairy  \n",
       "0      0      0  \n",
       "1      0      1  \n",
       "2      0      0  \n",
       "3      0      0  \n",
       "4      0      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('image_tagging/train.csv', nrows=10000) # set limit, delete \"nrows\" to undo\n",
    "train.drop(['Name'],axis=1,inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e608948-edf4-4d77-8002-f66cec802446",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Key', 'Type', 'normal', 'fire', 'water', 'grass', 'electric', 'ice',\n",
       "       'fighting', 'poison', 'ground', 'flying', 'psychic', 'bug', 'rock',\n",
       "       'ghost', 'dragon', 'dark', 'steel', 'fairy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c32a0646-903e-4a21-96bc-2bd60a1745a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:18<00:00, 549.96it/s]\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DATASET = \"/blue/rcstudents/smaley/pokegan/customsprites/blk_bg/input\"\n",
    "IMAGE_SIZE = (256,256,3)\n",
    "\n",
    "train_image = []\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    # we want them to be 256x256 images \n",
    "    img = image.load_img(f\"{TRAINING_DATASET}/{train.at[i, 'Key']}.png\",target_size=IMAGE_SIZE)\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    train_image.append(img)\n",
    "X = np.array(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aba3a06-ec18-4c64-b517-4226a307da76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 256, 256, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87b2296a-7b6a-4ca5-8100-e47e918ed5be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1482f04c7588>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "740a7a2a-0d8c-4745-b508-9301d14d35da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'grass, psychic'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Type'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39ab4779-ae21-42da-9355-e9635bbe5387",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 18)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(train.drop(['Key', 'Type'],axis=1))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb16055b-10d7-49d9-90ef-80eaf6a899d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dd7c451-612f-4ea0-8d99-7036599aeb61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=(5, 5), activation=\"relu\", input_shape=IMAGE_SIZE))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(18, activation='sigmoid')) # make equal to num classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b71a67de-45a7-451c-9577-a85d3a17683d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 252, 252, 16)      1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 126, 126, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 126, 126, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 122, 122, 32)      12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 61, 61, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 61, 61, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 57, 57, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 18)                1170      \n",
      "=================================================================\n",
      "Total params: 1,356,978\n",
      "Trainable params: 1,356,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c1c138e-2db0-41c2-a086-e7c4c1da0992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b9f431d-8481-44ac-b864-260f3e1991cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node sequential/conv2d/Conv2D (defined at <ipython-input-14-65db1493896e>:1) ]] [Op:__inference_train_function_1455]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-65db1493896e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/blue/daisyw/smaley/.conda/envs/type_prediction/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/blue/daisyw/smaley/.conda/envs/type_prediction/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/blue/daisyw/smaley/.conda/envs/type_prediction/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/blue/daisyw/smaley/.conda/envs/type_prediction/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/blue/daisyw/smaley/.conda/envs/type_prediction/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/blue/daisyw/smaley/.conda/envs/type_prediction/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/blue/daisyw/smaley/.conda/envs/type_prediction/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/blue/daisyw/smaley/.conda/envs/type_prediction/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/blue/daisyw/smaley/.conda/envs/type_prediction/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node sequential/conv2d/Conv2D (defined at <ipython-input-14-65db1493896e>:1) ]] [Op:__inference_train_function_1455]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1abd443-4a33-49ef-8345-e665c9738257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('50_epoch.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ab41c6-ee3c-4d66-accb-7fc43c657d95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "file_path = \"image_tagging/all_pokemon_to_type.csv\"\n",
    "pokedex = {}\n",
    "\n",
    "with open(file_path, mode='r') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    for row in csv_reader:\n",
    "        key = row['Key']\n",
    "        value = {col: row[col] for col in row if col != 'Key'}\n",
    "        pokedex[key] = value\n",
    "\n",
    "print(pokedex[\"338.287i\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc43668-6c7d-47b5-9b73-3bd64465bffe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Constants\n",
    "GRID_SIZE = 8  # 8x8 grid\n",
    "OUTPUT_FILE = \"predictions_grid.png\"  # Output file name\n",
    "\n",
    "# Variables\n",
    "count = 0\n",
    "fig, axes = plt.subplots(GRID_SIZE, GRID_SIZE, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate through the dataset\n",
    "for idx, file_name in enumerate(os.listdir(TRAINING_DATASET)):\n",
    "    if count >= GRID_SIZE * GRID_SIZE:  # Limit to 64 images\n",
    "        break\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    img_path = os.path.join(TRAINING_DATASET, file_name)\n",
    "    img = image.load_img(img_path, target_size=IMAGE_SIZE)\n",
    "    img_array = image.img_to_array(img) / 255.0  # Normalize\n",
    "    classes = np.array(train.columns[2:])\n",
    "    \n",
    "    # Make predictions\n",
    "    proba = model.predict(img_array.reshape(1,256,256,3))\n",
    "    top_2 = np.argsort(proba[0])[:-3:-1]  # Get top 2 predictions\n",
    "    top_2_predictions = [f\"{classes[i]} ({proba[0][i]:.2f})\" for i in top_2]\n",
    "    \n",
    "    # Get ground truth\n",
    "    ground_truth = pokedex[file_name[:-4]][\"Type\"]\n",
    "    \n",
    "    # Plot image in grid\n",
    "    axes[idx].imshow(img)\n",
    "    axes[idx].axis('off')  # Turn off axis\n",
    "    axes[idx].set_title(f\"P: {', '.join(top_2_predictions)}\\nA: {ground_truth}\", fontsize=6)\n",
    "    \n",
    "    count += 1\n",
    "\n",
    "# Adjust layout and save the grid\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_FILE, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f24883-ab7e-4830-8f30-b7ffc6412c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "type_prediction",
   "language": "python",
   "name": "type_prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
